{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Sentiment From Product Reviews\n",
    "\n",
    "\n",
    "The goal of this first notebook is to explore logistic regression and feature engineering with existing Turi Create functions.\n",
    "\n",
    "In this notebook you will use product review data from Amazon.com to predict whether the sentiments about a product (from its reviews) are positive or negative.\n",
    "\n",
    "* Use SFrames to do some feature engineering\n",
    "* Train a logistic regression model to predict the sentiment of product reviews.\n",
    "* Inspect the weights (coefficients) of a trained logistic regression model.\n",
    "* Make a prediction (both class and probability) of sentiment for a new product review.\n",
    "* Given the logistic regression weights, predictors and ground truth labels, write a function to compute the **accuracy** of the model.\n",
    "* Inspect the coefficients of the logistic regression model and interpret their meanings.\n",
    "* Compare multiple logistic regression models.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Neccessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import string\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We will use a dataset consisting of baby product reviews on Amazon.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('amazon_baby.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see a preview of what the dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Planetwise Flannel Wipes</td>\n",
       "      <td>These flannel wipes are OK, but in my opinion ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183531 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "0                                Planetwise Flannel Wipes   \n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \n",
       "0       These flannel wipes are OK, but in my opinion ...       3  \n",
       "1       it came early and was not disappointed. i love...       5  \n",
       "2       Very soft and comfortable and warmer than it l...       5  \n",
       "3       This is a product well worth the purchase.  I ...       5  \n",
       "4       All of my kids have cried non-stop when I trie...       5  \n",
       "...                                                   ...     ...  \n",
       "183526  Such a great idea! very handy to have and look...       5  \n",
       "183527  This product rocks!  It is a great blend of fu...       5  \n",
       "183528  This item looks great and cool for my kids.......       5  \n",
       "183529  I am extremely happy with this product. I have...       5  \n",
       "183530  I love this product very mush . I have bought ...       5  \n",
       "\n",
       "[183531 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explore a specific example of a baby product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      The First Years Massaging Action Teether\n",
       "review                    A favorite in our house!\n",
       "rating                                           5\n",
       "Name: 269, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.iloc[269,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will perform 2 simple data transformations:\n",
    "\n",
    "1. Remove punctuation using [Python's built-in](https://docs.python.org/2/library/string.html) string functionality.\n",
    "2. Transform the reviews into word-counts.\n",
    "\n",
    "**Aside**. In this notebook, we remove all punctuations for the sake of simplicity. A smarter approach to punctuations would preserve phrases such as \"I'd\", \"would've\", \"hadn't\" and so forth. See [this page](https://www.cis.upenn.edu/~treebank/tokenization.html) for an example of smart handling of punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    text = text.translate(str.maketrans('','',string.punctuation)) \n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "products = products.fillna({'review':''})  # fill in N/A's in the review column\n",
    "products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us explore what the sample example above looks like after these 2 transformations. Here, each entry in the **word_count** column is a dictionary where the key is the word and the value is a count of the number of times the word occurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract sentiments\n",
    "\n",
    "We will **ignore** all reviews with *rating = 3*, since they tend to have a neutral sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166752"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "len(products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will assign reviews with a rating of 4 or higher to be *positive* reviews, while the ones with rating of 2 or lower are *negative*. For the sentiment column, we use +1 for the positive class label and -1 for the negative class label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Planetwise Wipe Pouch</td>\n",
       "      <td>it came early and was not disappointed. i love...</td>\n",
       "      <td>5</td>\n",
       "      <td>it came early and was not disappointed i love ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annas Dream Full Quilt with 2 Shams</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Very soft and comfortable and warmer than it l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>This is a product well worth the purchase.  I ...</td>\n",
       "      <td>5</td>\n",
       "      <td>This is a product well worth the purchase  I h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>All of my kids have cried non-stop when I trie...</td>\n",
       "      <td>5</td>\n",
       "      <td>All of my kids have cried nonstop when I tried...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n",
       "      <td>When the Binky Fairy came to our house, we did...</td>\n",
       "      <td>5</td>\n",
       "      <td>When the Binky Fairy came to our house we didn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183526</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>Such a great idea! very handy to have and look...</td>\n",
       "      <td>5</td>\n",
       "      <td>Such a great idea very handy to have and look ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183527</th>\n",
       "      <td>Baby Teething Necklace for Mom Pretty Donut Sh...</td>\n",
       "      <td>This product rocks!  It is a great blend of fu...</td>\n",
       "      <td>5</td>\n",
       "      <td>This product rocks  It is a great blend of fun...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183528</th>\n",
       "      <td>Abstract 2 PK Baby / Toddler Training Cup (Pink)</td>\n",
       "      <td>This item looks great and cool for my kids.......</td>\n",
       "      <td>5</td>\n",
       "      <td>This item looks great and cool for my kidsI kn...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183529</th>\n",
       "      <td>Baby Food Freezer Tray - Bacteria Resistant, B...</td>\n",
       "      <td>I am extremely happy with this product. I have...</td>\n",
       "      <td>5</td>\n",
       "      <td>I am extremely happy with this product I have ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183530</th>\n",
       "      <td>Best 2 Pack Baby Car Shade for Kids - Window S...</td>\n",
       "      <td>I love this product very mush . I have bought ...</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this product very mush  I have bought m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166752 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "1                                   Planetwise Wipe Pouch   \n",
       "2                     Annas Dream Full Quilt with 2 Shams   \n",
       "3       Stop Pacifier Sucking without tears with Thumb...   \n",
       "4       Stop Pacifier Sucking without tears with Thumb...   \n",
       "5       Stop Pacifier Sucking without tears with Thumb...   \n",
       "...                                                   ...   \n",
       "183526  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183527  Baby Teething Necklace for Mom Pretty Donut Sh...   \n",
       "183528   Abstract 2 PK Baby / Toddler Training Cup (Pink)   \n",
       "183529  Baby Food Freezer Tray - Bacteria Resistant, B...   \n",
       "183530  Best 2 Pack Baby Car Shade for Kids - Window S...   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "1       it came early and was not disappointed. i love...       5   \n",
       "2       Very soft and comfortable and warmer than it l...       5   \n",
       "3       This is a product well worth the purchase.  I ...       5   \n",
       "4       All of my kids have cried non-stop when I trie...       5   \n",
       "5       When the Binky Fairy came to our house, we did...       5   \n",
       "...                                                   ...     ...   \n",
       "183526  Such a great idea! very handy to have and look...       5   \n",
       "183527  This product rocks!  It is a great blend of fu...       5   \n",
       "183528  This item looks great and cool for my kids.......       5   \n",
       "183529  I am extremely happy with this product. I have...       5   \n",
       "183530  I love this product very mush . I have bought ...       5   \n",
       "\n",
       "                                             review_clean  sentiment  \n",
       "1       it came early and was not disappointed i love ...          1  \n",
       "2       Very soft and comfortable and warmer than it l...          1  \n",
       "3       This is a product well worth the purchase  I h...          1  \n",
       "4       All of my kids have cried nonstop when I tried...          1  \n",
       "5       When the Binky Fairy came to our house we didn...          1  \n",
       "...                                                   ...        ...  \n",
       "183526  Such a great idea very handy to have and look ...          1  \n",
       "183527  This product rocks  It is a great blend of fun...          1  \n",
       "183528  This item looks great and cool for my kidsI kn...          1  \n",
       "183529  I am extremely happy with this product I have ...          1  \n",
       "183530  I love this product very mush  I have bought m...          1  \n",
       "\n",
       "[166752 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see that the dataset contains an extra column called **sentiment** which is either positive (+1) or negative (-1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform a train/test split with 80% of the data in the training set and 20% of the data in the test set. However, this notebook uses the indexes from the respective json files to get the indexes for train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train length : 133416\n",
      "test length : 33336\n"
     ]
    }
   ],
   "source": [
    "# Load the json files as lists consisting the indices for the train_data and the test_data\n",
    "train_indices = pd.read_json('module-2-assignment-train-idx.json')\n",
    "train_indices = train_indices.rename({0: 'indices'}, axis=1)\n",
    "train_indices = list(train_indices['indices']) # This ensures that the indices are not stored as list of lists\n",
    "\n",
    "test_indices = pd.read_json('module-2-assignment-test-idx.json')\n",
    "test_indices = test_indices.rename({0: 'indices'}, axis=1)\n",
    "test_indices = list(test_indices['indices']) # This ensures that the indices are not stored as list of lists\n",
    "\n",
    "# Filter the train_data and test_data based on the train_indices and test_indices\n",
    "train_data = products.iloc[train_indices]\n",
    "test_data = products.iloc[test_indices]\n",
    "\n",
    "print('train length :', len(train_data))\n",
    "print('test length :', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the word count vector for each review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compute the word count for each word that appears in the reviews. A vector consisting of word counts is often referred to as bag-of-word features. Since most words occur in only a few reviews, word count vectors are sparse. For this reason, scikit-learn and many other tools use sparse matrices to store a collection of word count vectors. Refer to appropriate manuals to produce sparse word count vectors. General steps for extracting word count vectors are as follows:\n",
    "\n",
    "* Learn a vocabulary (set of all words) from the training data. Only the words that show up in the training data will be considered for feature extraction.\n",
    "* Compute the occurrences of the words in each review and collect them into a row vector.\n",
    "* Build a sparse matrix where each row is the word count vector for the corresponding review. Call this matrix train_matrix.\n",
    "* Using the same mapping between words and columns, convert the test data into a sparse matrix test_matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that the test data must be transformed in the same way as the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a sentiment classifier with logistic regression\n",
    "\n",
    "We will now use logistic regression to create a sentiment classifier on the training data. Learn a logistic regression classifier using the training data. If you are using scikit-learn, you should create an instance of the LogisticRegression class and then call the method fit() to train the classifier. This model should use the sparse word count matrix **`train_matrix` as features** and the **column sentiment of `train_data` as the target**. Use the default values for other parameters. Call this model sentiment_model.\n",
    "\n",
    "**Note:** This line may take 1-2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Details :  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False) \n",
      "\n",
      "Sentiment Model Coefficients :\n",
      " [[-6.28825429e-01  1.10286789e-03  8.64651593e-03 ...  1.49255140e-03\n",
      "   1.07351416e-03 -4.16512629e-04]] \n",
      "\n",
      "Number of Sentiment Model Coefficients :  121712\n",
      "90353 coefficients have weights >=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ahmed ismail khalid\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "sentiment_model = clf.fit(train_matrix, train_data['sentiment'])\n",
    "\n",
    "print('Classifier Details : ',clf, '\\n')\n",
    "print('Sentiment Model Coefficients :\\n',sentiment_model.coef_,'\\n')\n",
    "print('Number of Sentiment Model Coefficients : ', sentiment_model.coef_.size)\n",
    "\n",
    "# The code below is to answer the following quiz question\n",
    "non_zero_coefs = (sentiment_model.coef_>= 0).sum()\n",
    "total_num_coefs = np.size(sentiment_model.coef_) # used in Week 3 Quiz\n",
    "print(non_zero_coefs, 'coefficients have weights >=0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be over 100,000 coefficients in this sentiment_model. Recall from the lecture that positive weights w_j correspond to weights that cause positive sentiment, while negative weights correspond to negative sentiment. Calculate the number of positive (>= 0, which is actually nonnegative) coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "non_zero_coefs": "90353"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz : How many weights are >= 0? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b> Answer : {{non_zero_coefs}} coefficients have weights >=0 </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making predictions with logistic regression\n",
    "\n",
    "Now that a model is trained, we can make predictions on the **test data**. In this section, we will explore this in the context of 3 examples in the test dataset.  We refer to this set of 3 examples as the **sample_test_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Our Baby Girl Memory Book</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>5</td>\n",
       "      <td>Absolutely love it and all of the Scripture in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Wall Decor Removable Decal Sticker - Colorful ...</td>\n",
       "      <td>Would not purchase again or recommend. The dec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Would not purchase again or recommend The deca...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>New Style Trailing Cherry Blossom Tree Decal R...</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>1</td>\n",
       "      <td>Was so excited to get this product for my baby...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  \\\n",
       "59                          Our Baby Girl Memory Book   \n",
       "71  Wall Decor Removable Decal Sticker - Colorful ...   \n",
       "91  New Style Trailing Cherry Blossom Tree Decal R...   \n",
       "\n",
       "                                               review  rating  \\\n",
       "59  Absolutely love it and all of the Scripture in...       5   \n",
       "71  Would not purchase again or recommend. The dec...       2   \n",
       "91  Was so excited to get this product for my baby...       1   \n",
       "\n",
       "                                         review_clean  sentiment  \n",
       "59  Absolutely love it and all of the Scripture in...          1  \n",
       "71  Would not purchase again or recommend The deca...         -1  \n",
       "91  Was so excited to get this product for my baby...         -1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data = test_data[10:13]\n",
    "sample_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's dig deeper into the first row of the sample_test_data. Here's the full review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Absolutely love it and all of the Scripture in it.  I purchased the Baby Boy version for my grandson when he was born and my daughter-in-law was thrilled to receive the same book again.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[0]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That review seems pretty positive.\n",
    "\n",
    "Now, let's see what the next row of the sample_test_data looks like. As we could guess from the rating (-1), the review is quite negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Would not purchase again or recommend. The decals were thick almost plastic like and were coming off the wall as I was applying them! The would NOT stick! Literally stayed stuck for about 5 minutes then started peeling off.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_data.iloc[1]['review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make a **class** prediction for the **sample_test_data**. The `sentiment_model` should predict **+1** if the sentiment is positive and **-1** if the sentiment is negative. Recall from the lecture that the **score** (sometimes called **margin**) for the logistic regression model  is defined as:\n",
    "\n",
    "$$\n",
    "\\mbox{score}_i = \\mathbf{w}^T h(\\mathbf{x}_i)\n",
    "$$ \n",
    "\n",
    "where $h(\\mathbf{x}_i)$ represents the features for example $i$.  We will write some code to obtain the **scores** using Turi Create. For each row, the **score** (or margin) is a number in the range **[-inf, inf]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.85336487,  -3.16175571, -10.11461459])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting sentiment\n",
    "\n",
    "These scores can be used to make class predictions as follows:\n",
    "\n",
    "$$\n",
    "\\hat{y} = \n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      +1 & \\mathbf{w}^T h(\\mathbf{x}_i) > 0 \\\\\n",
    "      -1 & \\mathbf{w}^T h(\\mathbf{x}_i) \\leq 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Using scores, write code to calculate $\\hat{y}$, the class predictions for **sample_test_data**\n",
    "\n",
    "**Checkpoint:** Make sure your class predictions match with the ones obtained from sentiment_model. The logistic regression classifier in scikit-learn comes with the predict function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from code            :  [1, -1, -1]\n",
      "Predictions from sentiment_model :  [1, -1, -1]\n"
     ]
    }
   ],
   "source": [
    "# Calculating predictions\n",
    "predictions = [1 if score > 0 else -1 for score in scores]\n",
    "\n",
    "# Checkpoint : Making sure predictions match the ones obtained from sentiment_model\n",
    "predictions_checkpoint = clf.predict(sample_test_matrix)\n",
    "\n",
    "print('Predictions from code            : ', predictions)\n",
    "print('Predictions from sentiment_model : ', predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability predictions\n",
    "\n",
    "Recall from the lectures that we can also calculate the probability predictions from the scores using:\n",
    "$$\n",
    "P(y_i = +1 | \\mathbf{x}_i,\\mathbf{w}) = \\frac{1}{1 + \\exp(-\\mathbf{w}^T h(\\mathbf{x}_i))}.\n",
    "$$\n",
    "\n",
    "Using the variable **scores** calculated previously, write code to calculate the probability that a sentiment is positive using the above formula. For each row, the probabilities should be a number in the range **[0, 1]**.\n",
    "\n",
    "**Checkpoint:** Make sure your probability predictions match the ones obtained from sentiment_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from code            :  [9.92258321e-01 4.06305612e-02 4.04819213e-05]\n",
      "Predictions from sentiment_model : \n",
      " [[7.74167918e-03 9.92258321e-01]\n",
      " [9.59369439e-01 4.06305612e-02]\n",
      " [9.99959518e-01 4.04819213e-05]]\n",
      "\n",
      " {'First': 0.9922583208242403, 'Second': 0.040630561175331814, 'Third': 4.048192132535376e-05} \n",
      "\n",
      "\n",
      "Third model has the lowest probability of being classified as positive review\n"
     ]
    }
   ],
   "source": [
    "# Calculating probabilty predictions\n",
    "probability_predictions = 1 / (1 + np.exp(-scores))\n",
    "\n",
    "# Checkpoint : Making sure probabilty predictions match the ones obtained from sentiment_model\n",
    "probability_predictions_checkpoint = clf.predict_proba(sample_test_matrix)\n",
    "\n",
    "print('Predictions from code            : ', probability_predictions)\n",
    "print('Predictions from sentiment_model : \\n', probability_predictions_checkpoint)\n",
    "\n",
    "\n",
    "# The code below is to answer the following quiz question \n",
    "\n",
    "lowest = []\n",
    "for i in range(len(probability_predictions_checkpoint)) :\n",
    "    lowest.append(probability_predictions_checkpoint[i][1])\n",
    "    \n",
    "model_names = ['First', 'Second', 'Third']\n",
    "\n",
    "lowest_dict = dict(zip(model_names, lowest))\n",
    "lowest_index = min(lowest_dict, key=lowest_dict.get)\n",
    "\n",
    "print('\\n',lowest_dict,'\\n\\n')\n",
    "print(lowest_index, 'model has the lowest probability of being classified as positive review')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "lowest_index": "Third"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz : Of the three data points in `sample_test_data`, which one (first, second, or third) has the *lowest probability* of being classified as a positive review? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b> Answer : {{lowest_index}} model has the lowest probability of being classified as positive review </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the most positive (and negative) review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now turn to examining the full test dataset, test_data, and use sklearn.linear_model.LogisticRegression to form predictions on all of the test data points.\n",
    "\n",
    "Using the `sentiment_model`, find the 20 reviews in the entire **test_data** with the **highest probability** of being classified as a **positive review**. We refer to these as the **\"most positive reviews.\"**\n",
    "\n",
    "To calculate these top-20 reviews, use the following steps:\n",
    "1.  Make probability predictions on **test_data** using the `sentiment_model`.\n",
    "2.  Sort the data according to those predictions and pick the top 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items represented in the 20 most positive reviews are : \n",
      "\n",
      "Roan Rocco Classic Pram Stroller 2-in-1 with Bassinet and Seat Unit - Coffee\n",
      "Graco FastAction Fold Jogger Click Connect Stroller, Grapeade\n",
      "Infantino Wrap and Tie Baby Carrier, Black Blueberries\n",
      "Baby Einstein Around The World Discovery Center\n",
      "Britax 2012 B-Agile Stroller, Red\n",
      "Graco Pack 'n Play Element Playard - Flint\n",
      "Evenflo X Sport Plus Convenience Stroller - Christina\n",
      "Diono RadianRXT Convertible Car Seat, Plum\n",
      "Fisher-Price Cradle 'N Swing,  My Little Snugabunny\n",
      "Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
      "Stork Craft Beatrice Combo Tower Chest, White\n",
      "Buttons Cloth Diaper Cover - One Size - 8 Color Options\n",
      "Britax Boulevard 70-G3 Convertible Car Seat Seat, Onyx\n",
      "Baby Jogger City Mini GT Single Stroller, Shadow/Orange\n",
      "P'Kolino Silly Soft Seating in Tias, Green\n",
      "Baby Jogger City Mini GT Double Stroller, Shadow/Orange\n",
      "Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
      "Simple Wishes Hands-Free Breastpump Bra, Pink, XS-L\n",
      "Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatware, Bowl, Plate, Tumbler Set, Colorful\n",
      "Summer Infant Wide View Digital Color Video Monitor\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ahmed ismail khalid\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "scores_test = sentiment_model.decision_function(test_matrix)\n",
    "predictions = 1/(1+np.exp(-scores_test))\n",
    "\n",
    "\n",
    "test_data['predictions'] = predictions\n",
    "pos_test_data = test_data.sort_values(by='predictions',ascending=False).iloc[0:20]\n",
    "most_positive_reviews = pos_test_data['review']\n",
    "\n",
    "# The code below is to answer the following quiz question\n",
    "positive_items = pos_test_data['name'].unique().tolist()\n",
    "\n",
    "print('Items represented in the 20 most positive reviews are : \\n')\n",
    "for product in positive_items :\n",
    "    print(product)\n",
    "    \n",
    "pos_test_data\n",
    "\n",
    "print(len(positive_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "positive_items": "[&#39;Roan Rocco Classic Pram Stroller 2-in-1 with Bassinet and Seat Unit - Coffee&#39;,\n &#39;Graco FastAction Fold Jogger Click Connect Stroller, Grapeade&#39;,\n &#39;Infantino Wrap and Tie Baby Carrier, Black Blueberries&#39;,\n &#39;Baby Einstein Around The World Discovery Center&#39;,\n &#39;Britax 2012 B-Agile Stroller, Red&#39;,\n &quot;Graco Pack &#39;n Play Element Playard - Flint&quot;,\n &#39;Evenflo X Sport Plus Convenience Stroller - Christina&#39;,\n &#39;Diono RadianRXT Convertible Car Seat, Plum&#39;,\n &quot;Fisher-Price Cradle &#39;N Swing,  My Little Snugabunny&quot;,\n &#39;Mamas &amp; Papas 2014 Urbo2 Stroller - Black&#39;,\n &#39;Stork Craft Beatrice Combo Tower Chest, White&#39;,\n &#39;Buttons Cloth Diaper Cover - One Size - 8 Color Options&#39;,\n &#39;Britax Boulevard 70-G3 Convertible Car Seat Seat, Onyx&#39;,\n &#39;Baby Jogger City Mini GT Single Stroller, Shadow/Orange&#39;,\n &quot;P&#39;Kolino Silly Soft Seating in Tias, Green&quot;,\n &#39;Baby Jogger City Mini GT Double Stroller, Shadow/Orange&#39;,\n &#39;Evenflo 6 Pack Classic Glass Bottle, 4-Ounce&#39;,\n &#39;Simple Wishes Hands-Free Breastpump Bra, Pink, XS-L&#39;,\n &#39;Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatware, Bowl, Plate, Tumbler Set, Colorful&#39;,\n &#39;Summer Infant Wide View Digital Color Video Monitor&#39;]"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz : Which of the following products are represented in the 20 most positive reviews? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer : The products represented as the 20 most positive reviews are :  </b></font> \n",
    "<font color = 'lightslategray'><b> <p>{{positive_items}}</p> </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us repeat this exercise to find the \"most negative reviews.\" Use the prediction probabilities to find the  20 reviews in the **test_data** with the **lowest probability** of being classified as a **positive review**. Repeat the same steps above but make sure you **sort in the opposite order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items represented in the 20 most negative reviews are : \n",
      "\n",
      "The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit\n",
      "Fisher-Price Ocean Wonders Aquarium Bouncer\n",
      "Levana Safe N'See Digital Video Baby Monitor with Talk-to-Baby Intercom and Lullaby Control (LV-TW501)\n",
      "VTech Communications Safe &amp; Sounds Full Color Video and Audio Monitor\n",
      "Adiri BPA Free Natural Nurser Ultimate Bottle Stage 1 White, Slow Flow (0-3 months)\n",
      "Safety 1st High-Def Digital Monitor\n",
      "One Step Ahead Hide-Away Extra Long Bed Rail\n",
      "Cloth Diaper Sprayer--styles may vary\n",
      "Baby Trend Inertia Infant Car Seat - Horizon\n",
      "Snuza Portable Baby Movement Monitor\n",
      "Samsung SEW-3037W Wireless Pan Tilt Video Baby Monitor Infrared Night Vision and Zoom, 3.5 inch\n",
      "Regalo My Cot Portable Bed, Royal Blue\n",
      "Ellaroo Mei Tai Baby Carrier - Hershey\n",
      "Peg-Perego Tatamia High Chair, White Latte\n",
      "Baby Jogger Summit XC Double Stroller, Red/Black\n",
      "Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
      "Safety 1st Deluxe 4-in-1 Bath Station\n",
      "Motorola Digital Video Baby Monitor with Room Temperature Thermometer\n",
      "Philips AVENT Newborn Starter Set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>94560</th>\n",
       "      <td>The First Years True Choice P400 Premium Digit...</td>\n",
       "      <td>Note: we never installed batteries in these un...</td>\n",
       "      <td>1</td>\n",
       "      <td>Note we never installed batteries in these uni...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.707690e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16042</th>\n",
       "      <td>Fisher-Price Ocean Wonders Aquarium Bouncer</td>\n",
       "      <td>We have not had ANY luck with Fisher-Price pro...</td>\n",
       "      <td>2</td>\n",
       "      <td>We have not had ANY luck with FisherPrice prod...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.529871e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120209</th>\n",
       "      <td>Levana Safe N'See Digital Video Baby Monitor w...</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is the first review I have ever written o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.683606e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155287</th>\n",
       "      <td>VTech Communications Safe &amp;amp; Sounds Full Co...</td>\n",
       "      <td>This is my second video monitoring system, the...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is my second video monitoring system the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>6.560807e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48694</th>\n",
       "      <td>Adiri BPA Free Natural Nurser Ultimate Bottle ...</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>2</td>\n",
       "      <td>I will try to write an objective review of the...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.547734e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53207</th>\n",
       "      <td>Safety 1st High-Def Digital Monitor</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>1</td>\n",
       "      <td>We bought this baby monitor to replace a diffe...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.872547e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95420</th>\n",
       "      <td>One Step Ahead Hide-Away Extra Long Bed Rail</td>\n",
       "      <td>I bought a brand new 56\" hide-away bed safety ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought a brand new 56 hideaway bed safety ra...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.126846e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81332</th>\n",
       "      <td>Cloth Diaper Sprayer--styles may vary</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>1</td>\n",
       "      <td>I bought this sprayer out of desperation durin...</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.058510e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176046</th>\n",
       "      <td>Baby Trend Inertia Infant Car Seat - Horizon</td>\n",
       "      <td>I really wanted to love this seat; however, I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I really wanted to love this seat however I wo...</td>\n",
       "      <td>-1</td>\n",
       "      <td>9.035887e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94389</th>\n",
       "      <td>Snuza Portable Baby Movement Monitor</td>\n",
       "      <td>I would have given the product 4 stars for whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>I would have given the product 4 stars for whi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.284190e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167249</th>\n",
       "      <td>Samsung SEW-3037W Wireless Pan Tilt Video Baby...</td>\n",
       "      <td>Reviewers. You failed me!This thing worked for...</td>\n",
       "      <td>1</td>\n",
       "      <td>Reviewers You failed meThis thing worked for 2...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.480523e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31741</th>\n",
       "      <td>Regalo My Cot Portable Bed, Royal Blue</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>If I could give this product zero stars I woul...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.514077e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59546</th>\n",
       "      <td>Ellaroo Mei Tai Baby Carrier - Hershey</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>1</td>\n",
       "      <td>This is basically an overpriced piece of fabri...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.738952e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76000</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I ordered this high chair with the brown seat ...</td>\n",
       "      <td>1</td>\n",
       "      <td>I ordered this high chair with the brown seat ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.781042e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96572</th>\n",
       "      <td>Baby Jogger Summit XC Double Stroller, Red/Black</td>\n",
       "      <td>Received Jogger as a shower gift so it sat in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Received Jogger as a shower gift so it sat in ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.022657e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77072</th>\n",
       "      <td>Safety 1st Exchangeable Tip 3 in 1 Thermometer</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>1</td>\n",
       "      <td>I thought it sounded great to have different t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.172607e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>Safety 1st Deluxe 4-in-1 Bath Station</td>\n",
       "      <td>This item is junk.  I originally chose it beca...</td>\n",
       "      <td>1</td>\n",
       "      <td>This item is junk  I originally chose it becau...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.426882e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113995</th>\n",
       "      <td>Motorola Digital Video Baby Monitor with Room ...</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITOR!I purchased this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DO NOT BUY THIS BABY MONITORI purchased this m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2.947483e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75994</th>\n",
       "      <td>Peg-Perego Tatamia High Chair, White Latte</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>2</td>\n",
       "      <td>I can see why there are so many good reviews o...</td>\n",
       "      <td>-1</td>\n",
       "      <td>3.832001e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10677</th>\n",
       "      <td>Philips AVENT Newborn Starter Set</td>\n",
       "      <td>It's 3am in the morning and needless to say, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>Its 3am in the morning and needless to say thi...</td>\n",
       "      <td>-1</td>\n",
       "      <td>4.068577e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     name  \\\n",
       "94560   The First Years True Choice P400 Premium Digit...   \n",
       "16042         Fisher-Price Ocean Wonders Aquarium Bouncer   \n",
       "120209  Levana Safe N'See Digital Video Baby Monitor w...   \n",
       "155287  VTech Communications Safe &amp; Sounds Full Co...   \n",
       "48694   Adiri BPA Free Natural Nurser Ultimate Bottle ...   \n",
       "53207                 Safety 1st High-Def Digital Monitor   \n",
       "95420        One Step Ahead Hide-Away Extra Long Bed Rail   \n",
       "81332               Cloth Diaper Sprayer--styles may vary   \n",
       "176046       Baby Trend Inertia Infant Car Seat - Horizon   \n",
       "94389                Snuza Portable Baby Movement Monitor   \n",
       "167249  Samsung SEW-3037W Wireless Pan Tilt Video Baby...   \n",
       "31741              Regalo My Cot Portable Bed, Royal Blue   \n",
       "59546              Ellaroo Mei Tai Baby Carrier - Hershey   \n",
       "76000          Peg-Perego Tatamia High Chair, White Latte   \n",
       "96572    Baby Jogger Summit XC Double Stroller, Red/Black   \n",
       "77072      Safety 1st Exchangeable Tip 3 in 1 Thermometer   \n",
       "1116                Safety 1st Deluxe 4-in-1 Bath Station   \n",
       "113995  Motorola Digital Video Baby Monitor with Room ...   \n",
       "75994          Peg-Perego Tatamia High Chair, White Latte   \n",
       "10677                   Philips AVENT Newborn Starter Set   \n",
       "\n",
       "                                                   review  rating  \\\n",
       "94560   Note: we never installed batteries in these un...       1   \n",
       "16042   We have not had ANY luck with Fisher-Price pro...       2   \n",
       "120209  This is the first review I have ever written o...       1   \n",
       "155287  This is my second video monitoring system, the...       1   \n",
       "48694   I will try to write an objective review of the...       2   \n",
       "53207   We bought this baby monitor to replace a diffe...       1   \n",
       "95420   I bought a brand new 56\" hide-away bed safety ...       1   \n",
       "81332   I bought this sprayer out of desperation durin...       1   \n",
       "176046  I really wanted to love this seat; however, I ...       1   \n",
       "94389   I would have given the product 4 stars for whi...       1   \n",
       "167249  Reviewers. You failed me!This thing worked for...       1   \n",
       "31741   If I could give this product zero stars I woul...       1   \n",
       "59546   This is basically an overpriced piece of fabri...       1   \n",
       "76000   I ordered this high chair with the brown seat ...       1   \n",
       "96572   Received Jogger as a shower gift so it sat in ...       1   \n",
       "77072   I thought it sounded great to have different t...       1   \n",
       "1116    This item is junk.  I originally chose it beca...       1   \n",
       "113995  DO NOT BUY THIS BABY MONITOR!I purchased this ...       1   \n",
       "75994   I can see why there are so many good reviews o...       2   \n",
       "10677   It's 3am in the morning and needless to say, t...       1   \n",
       "\n",
       "                                             review_clean  sentiment  \\\n",
       "94560   Note we never installed batteries in these uni...         -1   \n",
       "16042   We have not had ANY luck with FisherPrice prod...         -1   \n",
       "120209  This is the first review I have ever written o...         -1   \n",
       "155287  This is my second video monitoring system the ...         -1   \n",
       "48694   I will try to write an objective review of the...         -1   \n",
       "53207   We bought this baby monitor to replace a diffe...         -1   \n",
       "95420   I bought a brand new 56 hideaway bed safety ra...         -1   \n",
       "81332   I bought this sprayer out of desperation durin...         -1   \n",
       "176046  I really wanted to love this seat however I wo...         -1   \n",
       "94389   I would have given the product 4 stars for whi...         -1   \n",
       "167249  Reviewers You failed meThis thing worked for 2...         -1   \n",
       "31741   If I could give this product zero stars I woul...         -1   \n",
       "59546   This is basically an overpriced piece of fabri...         -1   \n",
       "76000   I ordered this high chair with the brown seat ...         -1   \n",
       "96572   Received Jogger as a shower gift so it sat in ...         -1   \n",
       "77072   I thought it sounded great to have different t...         -1   \n",
       "1116    This item is junk  I originally chose it becau...         -1   \n",
       "113995  DO NOT BUY THIS BABY MONITORI purchased this m...         -1   \n",
       "75994   I can see why there are so many good reviews o...         -1   \n",
       "10677   Its 3am in the morning and needless to say thi...         -1   \n",
       "\n",
       "         predictions  \n",
       "94560   1.707690e-14  \n",
       "16042   2.529871e-14  \n",
       "120209  2.683606e-12  \n",
       "155287  6.560807e-12  \n",
       "48694   2.547734e-10  \n",
       "53207   3.872547e-10  \n",
       "95420   4.126846e-10  \n",
       "81332   8.058510e-10  \n",
       "176046  9.035887e-10  \n",
       "94389   1.284190e-09  \n",
       "167249  1.480523e-09  \n",
       "31741   1.514077e-09  \n",
       "59546   1.738952e-09  \n",
       "76000   1.781042e-09  \n",
       "96572   2.022657e-09  \n",
       "77072   2.172607e-09  \n",
       "1116    2.426882e-09  \n",
       "113995  2.947483e-09  \n",
       "75994   3.832001e-09  \n",
       "10677   4.068577e-09  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_test_data = test_data.sort_values(by='predictions',ascending=True).iloc[0:20]\n",
    "\n",
    "most_negative_reviews = neg_test_data['review']\n",
    "\n",
    "# The code below is to answer the following quiz question\n",
    "negative_items = neg_test_data['name'].unique().tolist()\n",
    "\n",
    "print('Items represented in the 20 most negative reviews are : \\n')\n",
    "for product in negative_items :\n",
    "    print(product)\n",
    "    \n",
    "neg_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "negative_items": "[&#39;The First Years True Choice P400 Premium Digital Monitor, 2 Parent Unit&#39;,\n &#39;Fisher-Price Ocean Wonders Aquarium Bouncer&#39;,\n &quot;Levana Safe N&#39;See Digital Video Baby Monitor with Talk-to-Baby Intercom and Lullaby Control (LV-TW501)&quot;,\n &#39;VTech Communications Safe &amp; Sounds Full Color Video and Audio Monitor&#39;,\n &#39;Adiri BPA Free Natural Nurser Ultimate Bottle Stage 1 White, Slow Flow (0-3 months)&#39;,\n &#39;Safety 1st High-Def Digital Monitor&#39;,\n &#39;One Step Ahead Hide-Away Extra Long Bed Rail&#39;,\n &#39;Cloth Diaper Sprayer--styles may vary&#39;,\n &#39;Baby Trend Inertia Infant Car Seat - Horizon&#39;,\n &#39;Snuza Portable Baby Movement Monitor&#39;,\n &#39;Samsung SEW-3037W Wireless Pan Tilt Video Baby Monitor Infrared Night Vision and Zoom, 3.5 inch&#39;,\n &#39;Regalo My Cot Portable Bed, Royal Blue&#39;,\n &#39;Ellaroo Mei Tai Baby Carrier - Hershey&#39;,\n &#39;Peg-Perego Tatamia High Chair, White Latte&#39;,\n &#39;Baby Jogger Summit XC Double Stroller, Red/Black&#39;,\n &#39;Safety 1st Exchangeable Tip 3 in 1 Thermometer&#39;,\n &#39;Safety 1st Deluxe 4-in-1 Bath Station&#39;,\n &#39;Motorola Digital Video Baby Monitor with Room Temperature Thermometer&#39;,\n &#39;Philips AVENT Newborn Starter Set&#39;]"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz : Which of the following products are represented in the 20 most negative reviews? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer : The products represented as the 20 most negative reviews are :  </b></font> \n",
    "<font color = 'lightslategray'><b> <p>{{negative_items}}</p> </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute accuracy of the classifier\n",
    "\n",
    "We will now evaluate the accuracy of the trained classifier. Recall that the accuracy is given by\n",
    "\n",
    "\n",
    "$$\n",
    "\\mbox{accuracy} = \\frac{\\mbox{# correctly classified examples}}{\\mbox{# total examples}}\n",
    "$$\n",
    "\n",
    "This can be computed as follows:\n",
    "\n",
    "* **Step 1:** Use the trained model to compute class predictions (**Hint:** Use the `predict` method)\n",
    "* **Step 2:** Count the number of data points when the predicted class labels match the ground truth labels (called `true_labels` below).\n",
    "* **Step 3:** Divide the total number of correct predictions by the total number of data points in the dataset.\n",
    "\n",
    "Complete the function below to compute the classification accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Model Accuracy on Test Data :  0.93\n"
     ]
    }
   ],
   "source": [
    "test_matrix_sentiment_model = vectorizer.transform(test_data['review_clean'])\n",
    "scores_test_sentiment_model = sentiment_model.decision_function(test_matrix_sentiment_model)\n",
    "predictions_test_sentiment_model = clf.predict(test_matrix_sentiment_model)\n",
    "\n",
    "correct_test = sum([1 if prediction == true_label else 0 for prediction, true_label\n",
    "                   in zip(predictions_test_sentiment_model, test_data['sentiment'])])\n",
    "\n",
    "sentiment_model_accuracy_test = round(correct_test/len(test_data['review_clean']),2)\n",
    "\n",
    "print('Sentiment Model Accuracy on Test Data : ', sentiment_model_accuracy_test)\n",
    "\n",
    "data_test_sentiment_model = {'predictions':predictions_test_sentiment_model, 'original':test_data['sentiment']}\n",
    "df_test_sentiment_model = pd.DataFrame(data=data_test_sentiment_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "sentiment_model_accuracy_test*100": "93.0"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz 1: What is the accuracy of the `sentiment_model` on the `test_data`? Round your answer to 2 decimal places (e.g. 0.76) </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer 1 : Sentiment Model has an accuracy of {{sentiment_model_accuracy_test*100}}%  </b></font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<font color = 'steelblue'><b> Quiz 2: Does a higher accuracy value on the `training_data` always imply that the classifier is better? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer 2 : No, as the this could imply overfitting on the training data as compared to generalizing on the data </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn another classifier with fewer words\n",
    "\n",
    "There were a lot of words in the model we trained above. We will now train a simpler logistic regression model using only a subset of words that occur in the reviews. For this assignment, we selected a 20 words to work with. These are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a new set of word count vectors using only these words. The CountVectorizer class has a parameter that lets you limit the choice of words when building word count vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute word count vectors for the training and test data and obtain the sparse matrices train_matrix_word_subset and test_matrix_word_subset, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a logistic regression model on a subset of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a logistic regression classifier with **train_matrix_word_subset** as features and **sentiment** as the target. Call this model **simple_model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_simple = LogisticRegression()\n",
    "simple_model = clf_simple.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us inspect the weights (coefficients) of the simple_model. First, build a table to store (word, coefficient) pairs. If you are using SFrame with scikit-learn, you can combine words with coefficients by running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love</td>\n",
       "      <td>1.363697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>0.943950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>easy</td>\n",
       "      <td>1.192219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>old</td>\n",
       "      <td>0.085424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>little</td>\n",
       "      <td>0.520174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>perfect</td>\n",
       "      <td>1.510263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>loves</td>\n",
       "      <td>1.673269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>well</td>\n",
       "      <td>0.503760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>able</td>\n",
       "      <td>0.190937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>car</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>broke</td>\n",
       "      <td>-1.652144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>less</td>\n",
       "      <td>-0.209348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>even</td>\n",
       "      <td>-0.511456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>waste</td>\n",
       "      <td>-2.034489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>disappointed</td>\n",
       "      <td>-2.348478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>work</td>\n",
       "      <td>-0.621307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>product</td>\n",
       "      <td>-0.320491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>money</td>\n",
       "      <td>-0.898062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>would</td>\n",
       "      <td>-0.362157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>return</td>\n",
       "      <td>-2.109815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  coefficient\n",
       "0           love     1.363697\n",
       "1          great     0.943950\n",
       "2           easy     1.192219\n",
       "3            old     0.085424\n",
       "4         little     0.520174\n",
       "5        perfect     1.510263\n",
       "6          loves     1.673269\n",
       "7           well     0.503760\n",
       "8           able     0.190937\n",
       "9            car     0.058813\n",
       "10         broke    -1.652144\n",
       "11          less    -0.209348\n",
       "12          even    -0.511456\n",
       "13         waste    -2.034489\n",
       "14  disappointed    -2.348478\n",
       "15          work    -0.621307\n",
       "16       product    -0.320491\n",
       "17         money    -0.898062\n",
       "18         would    -0.362157\n",
       "19        return    -2.109815"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coef_table = pd.DataFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})\n",
    "simple_model_coef_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the data frame by the coefficient value in descending order.\n",
    "\n",
    "Note: Make sure that the intercept term is excluded from this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 of the 20 coefficients in the simple_model_coef_table are positive for simple_model\n",
      "\n",
      "Words that are present in both simple_model and sentiment_model are : ['loves', 'perfect', 'love', 'easy', 'great', 'little', 'well', 'able', 'old', 'car']\n"
     ]
    }
   ],
   "source": [
    "simple_model_coef_table = simple_model_coef_table.sort_values(by='coefficient', ascending=False)\n",
    "simple_model_coef_table\n",
    "\n",
    "\n",
    "# The code below is to answer the following quiz questions\n",
    "\n",
    "count_positive = sum(simple_model_coef_table['coefficient'] > 0)\n",
    "print(count_positive, 'of the 20 coefficients in the simple_model_coef_table are positive for simple_model')\n",
    "\n",
    "positive_simple_model = simple_model_coef_table['word'][simple_model_coef_table['coefficient'] >= 0].tolist()\n",
    "\n",
    "vocab = list(vectorizer.vocabulary_.keys())\n",
    "coeffs = {vocab[i]: c for i, c in enumerate(sentiment_model.coef_[0])}\n",
    "\n",
    "common_dict = {k:v for k, v in coeffs.items() if k in significant_words}\n",
    "\n",
    "common_words = pd.DataFrame(common_dict.items(), columns=['word', 'simple_model coef'])\n",
    "common_words = pd.merge(simple_model_coef_table, common_words, how = 'left', on = 'word')\n",
    "common_words = common_words[common_words['coefficient'] >= 0]\n",
    "common_words = common_words['word'].tolist()\n",
    "\n",
    "print('\\nWords that are present in both simple_model and sentiment_model are :', common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "count_positive": "10",
     "positive_simple_model": "[&#39;loves&#39;,\n &#39;perfect&#39;,\n &#39;love&#39;,\n &#39;easy&#39;,\n &#39;great&#39;,\n &#39;little&#39;,\n &#39;well&#39;,\n &#39;able&#39;,\n &#39;old&#39;,\n &#39;car&#39;]"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz 1 : Consider the coefficients of simple_model. How many of the 20 coefficients (corresponding to the 20 significant_words) are positive for the simple_model? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer 1 : {{count_positive}} of the 20 coefficients in the simple_model_coef_table are positive for simple_model. These words are : </b></font>\n",
    "<font color = 'slategray'><b> <p>{{positive_simple_model}}</p> </b></font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<font color = 'steelblue'><b> Quiz 2 : Are the positive words in the simple_model also positive words in the sentiment_model? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer 2 : All the words present in the simple_model are also present in the sentiment_model. </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now compare the accuracy of the sentiment_model and the simple_model.\n",
    "\n",
    "First, compute the classification accuracy of the sentiment_model on the train_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Model Accuracy on Train Data :  0.95\n"
     ]
    }
   ],
   "source": [
    "predictions_train_sentiment_model = sentiment_model.predict(train_matrix)\n",
    "\n",
    "correct_train_sentiment_model = sum([1 if prediction == true_label else 0 for prediction, true_label\n",
    "                   in zip(predictions_train_sentiment_model, train_data['sentiment'])])\n",
    "\n",
    "sentiment_model_accuracy_train = round(correct_train_sentiment_model/len(train_data['review_clean']),2)\n",
    "\n",
    "print('Sentiment Model Accuracy on Train Data : ',sentiment_model_accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, compute the classification accuracy of the simple_model on the train_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Accuracy on Train Data :  0.87 \n",
      "\n",
      "Sentiment Model has the higher accuracy on TRAINING set with an accuracy of 0.95\n"
     ]
    }
   ],
   "source": [
    "predictions_train_simple_model = simple_model.predict(train_matrix_word_subset)\n",
    "\n",
    "correct_train_simple_model = sum([1 if prediction == true_label else 0 for prediction, true_label\n",
    "                   in zip(predictions_train_simple_model, train_data['sentiment'])])\n",
    "\n",
    "simple_model_accuracy_train = round(correct_train_simple_model/len(train_data['review_clean']),2)\n",
    "\n",
    "print('Simple Model Accuracy on Train Data : ',simple_model_accuracy_train,'\\n')\n",
    "\n",
    "\n",
    "# The code below is to answer the following quiz question\n",
    "if sentiment_model_accuracy_train > simple_model_accuracy_train :\n",
    "    accurate_train_model = 'Sentiment Model'\n",
    "    higher_accuracy_train = sentiment_model_accuracy_train\n",
    "    \n",
    "elif sentiment_model_accuracy_train < simple_model_accuracy_train :\n",
    "    accurate_train_model = 'Simple Model'\n",
    "    higher_accuracy_train = simple_model_accuracy_train\n",
    "    \n",
    "print(accurate_train_model, 'has the higher accuracy on TRAINING set with an accuracy of', higher_accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "accurate_train_model": "Sentiment Model",
     "higher_accuracy_train": "0.95"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz : Which model (sentiment_model or simple_model) has higher accuracy on the TRAINING set? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer : {{accurate_train_model}} has the higher accuracy on TRAINING set with an accuracy of {{higher_accuracy_train}} </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will repeat this exercise on the **test_data**. Start by computing the classification accuracy of the **sentiment_model** on the **test_data**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Model Accuracy on test Data :  0.93\n"
     ]
    }
   ],
   "source": [
    "predictions_test_sentiment_model = sentiment_model.predict(test_matrix)\n",
    "\n",
    "correct_test_sentiment_model = sum([1 if prediction == true_label else 0 for prediction, true_label\n",
    "                   in zip(predictions_test_sentiment_model, test_data['sentiment'])])\n",
    "\n",
    "sentiment_model_accuracy_test = round(correct_test_sentiment_model/len(test_data['review_clean']),2)\n",
    "\n",
    "print('Sentiment Model Accuracy on test Data : ',sentiment_model_accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, compute the classification accuracy of the simple_model on the test_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Model Accuracy on test Data :  0.87 \n",
      "\n",
      "Sentiment Model has the higher accuracy on TEST set with an accuracy of 0.93\n"
     ]
    }
   ],
   "source": [
    "predictions_test_simple_model = simple_model.predict(test_matrix_word_subset)\n",
    "\n",
    "correct_test_simple_model = sum([1 if prediction == true_label else 0 for prediction, true_label\n",
    "                   in zip(predictions_test_simple_model, test_data['sentiment'])])\n",
    "\n",
    "simple_model_accuracy_test = round(correct_test_simple_model/len(test_data['review_clean']),2)\n",
    "\n",
    "print('Simple Model Accuracy on test Data : ',simple_model_accuracy_test,'\\n')\n",
    "\n",
    "\n",
    "# The code below is to answer the following quiz question\n",
    "if sentiment_model_accuracy_test > simple_model_accuracy_test :\n",
    "    accurate_test_model = 'Sentiment Model'\n",
    "    higher_accuracy_test = sentiment_model_accuracy_test\n",
    "    \n",
    "elif sentiment_model_accuracy_test < simple_model_accuracy_test :\n",
    "    accurate_test_model = 'Simple Model'\n",
    "    higher_accuracy_test = simple_model_accuracy_test\n",
    "    \n",
    "print(accurate_test_model, 'has the higher accuracy on TEST set with an accuracy of', higher_accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "accurate_test_model": "Sentiment Model",
     "higher_accuracy_test": "0.93"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz : Which model (sentiment_model or simple_model) has higher accuracy on the TEST set? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer : {{accurate_test_model}} has the higher accuracy on TEST set with an accuracy of {{higher_accuracy_test}} </b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Majority class prediction\n",
    "\n",
    "It is quite common to use the **majority class classifier** as the a baseline (or reference) model for comparison with your classifier model. The majority classifier model predicts the majority class for all data points. At the very least, you should healthily beat the majority class classifier, otherwise, the model is (usually) pointless.\n",
    "\n",
    "What is the majority class in the **train_data**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Sentiment Class is the majority class in train set\n",
      "\n",
      "The accuracy of majority classifier on test data is : 0.84 \n",
      "\n",
      "Sentiment Model is definitely better than Majority Classifier as it has an accuracy of 0.93 compared to that of majority classifier having an accuarcy of 0.84\n"
     ]
    }
   ],
   "source": [
    "class_pos_train = sum(train_data['sentiment'] == 1)\n",
    "class_neg_train = sum(train_data['sentiment'] == -1)\n",
    "\n",
    "if class_pos_train > class_neg_train :\n",
    "    majority_train_class = 'Positive Sentiment Class'\n",
    "\n",
    "elif class_pos_train < class_neg_train :\n",
    "    majority_train_class = 'Negative Sentiment Class'\n",
    "    \n",
    "print(majority_train_class ,'is the majority class in train set')\n",
    "\n",
    "# The code below is to answer the following quiz questions \n",
    "majority_classifier_test_acc = round(max(class_pos_train,class_neg_train) / (class_pos_train + class_neg_train), 2)\n",
    "\n",
    "print('\\nThe accuracy of majority classifier on test data is :', majority_classifier_test_acc, '\\n')\n",
    "\n",
    "if sentiment_model_accuracy_test > majority_classifier_test_acc :\n",
    "    better_model = 'Sentiment Model is definitely better than Majority Classifier'\n",
    "\n",
    "elif sentiment_model_accuracy_test < majority_classifier_test_acc :\n",
    "    better_model = 'Sentiment Model is definitely not better than Majority Classifier'\n",
    "    \n",
    "print(better_model, 'as it has an accuracy of', sentiment_model_accuracy_test, 'compared to that of majority classifier' \n",
    "      ' having an accuarcy of', majority_classifier_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "variables": {
     "better_model": "Sentiment Model is definitely better than Majority Classifier",
     "majority_classifier_test_acc": "0.84"
    }
   },
   "source": [
    "<font color = 'steelblue'><b> Quiz 1 : Enter the accuracy of the majority class classifier model on the test_data. Round your answer to two decimal places (e.g. 0.76). </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer 1 : The accuracy of majority classifier on test data is {{majority_classifier_test_acc}} </b></font>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<font color = 'steelblue'><b> Quiz 2 : Is the sentiment_model definitely better than the majority class classifier (the baseline)? </b></font>\n",
    "\n",
    "<font color = 'mediumvioletred'><b>  Answer 2 : {{better_model}} </b></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
